---
title: "Discovering bad parametrization with SBC"
output: html_notebook
---

```{r setup, include = FALSE}
library(SBC); 
use_cmdstanr <- TRUE # Set to false to use rstan instead

if(use_cmdstanr) {
  library(cmdstanr)
} else {
  library(rstan)
}

options(mc.cores = parallel::detectCores())

# Uncomment below to have the fits evaluated in parallel
# However, as this example evaluates just a few fits, it
# is usually not worth the overhead.

# library(future)
# plan(multisession)

```


Premise: we mistakenly assume that Stan does parametrize the normal distribution
via mean and precision (like JAGS or INLA do). Since we want to put prior on the 
standard deviation (as is suggested on the prior choice wiki), we take standard deviation as the parameter and transform to precision $\tau = \frac{1}{\sigma^2}$.


TODO maybe start with prior predictive check to tune priors?

```{r}
stan_code_1 <- "
data {
  int N;
  vector<lower=0>[N] y;
}

parameters {
  real<lower = 0> shape;
  real<lower = 0> scale;  
}

model {
  y ~ gamma(shape, scale);
  shape ~ lognormal(0, 1);
  scale ~ lognormal(0, 1.5);
}
"
iter_warmup <- 1000
iter_sampling <- 500

if(use_cmdstanr) {
  model_1 <- cmdstan_model(write_stan_file(stan_code_1))

  sbc_backend_1 <- cmdstan_sample_SBC_backend(
    model_1, iter_warmup = iter_warmup, iter_sampling = iter_sampling, chains = 2)
} else {
  model_1 <- stan_model(model_code = stan_code_1)

  sbc_backend_1 <- rstan_sample_SBC_backend(
    model_1, iter = iter_sampling + iter_warmup, warmup = iter_warmup, chains = 2)
}

```

Build a generator to create simulated datasets.

```{r}
set.seed(21448857)
n_datasets <- 10

generator_func <- function(N) {
  shape <- rlnorm(1, meanlog =  0, sdlog = 1)
  scale <- rlnorm(1, meanlog = 0, sdlog = 1.5)
  
  y <- rgamma(N, shape = shape, scale = scale)
  if(any(y == 0)) {
    warning("Generated zero, replacing with small values")
    y[y == 0] <- .Machine$double.eps
  }
  
  list(
    parameters = list(
      shape = shape,
      scale = scale),
    generated = list(
      N = N,
      y = y)
  )
}


generator <- function_SBC_generator(generator_func, N = 40)
datasets <- generate_datasets(
  generator, 
  n_datasets)

```


```{r}
thin <- 4
results1 <- compute_results(datasets, sbc_backend_1, thin_ranks = thin)
```


10 simulations are enough to see something is wrong with the model. We even see the issue is primarily with the `scale` parameter!

```{r}
plot_ecdf_diff(results1)
```

So we see that the simulation does not match the model. In practice, the problem may lie with the simulation, with the model or both. Here, we'll assume that the simulation is correct - we really wanted to work with scale and fix the model to match. I.e. we still represent scale in our model, but invert it to get rate before using Stan's `gamma` distribution:


```{r}
stan_code_2 <- "
data {
  int N;
  vector<lower=0>[N] y;
}

parameters {
  real<lower = 0> shape;
  real<lower = 0> scale;  
}

model {
  y ~ gamma(shape, inv(scale));
  shape ~ lognormal(0, 1);
  scale ~ lognormal(0, 1.5);
}
"

if(use_cmdstanr) {
  model_2 <- cmdstan_model(write_stan_file(stan_code_2))

  sbc_backend_2 <- cmdstan_sample_SBC_backend(
    model_2, iter_warmup = iter_warmup, iter_sampling = iter_sampling, chains = 2)
} else {
  model_2 <- stan_model(model_code = stan_code_2)

  sbc_backend_2 <- rstan_sample_SBC_backend(
    model_2, iter = iter_sampling + iter_warmup, warmup = iter_warmup, chains = 2)
}


```


```{r}
results2 <- compute_results(datasets, sbc_backend_2, thin_ranks = thin)
```

No obvious problems here, but if we wanted to be sure, we should have ran a lot more simulations.

```{r}
plot_ecdf_diff(results2)
```


