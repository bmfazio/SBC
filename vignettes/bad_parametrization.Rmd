---
title: "Discovering bad parametrization with SBC"
output: html_notebook
---

```{r setup, include = FALSE}
library(SBC); library(cmdstanr)
```


Premise: we mistakenly assume that Stan does parametrize the normal distribution
via mean and precision (like JAGS or INLA do). Since we want to put prior on the 
standard deviation (as is suggested on the prior choice wiki), we take standard deviation as the parameter and transform to precision $\tau = \frac{1}{\sigma^2}$.


TODO maybe start with prior predictive check to tune priors?

```{r}
stan_code_1 <- "
data {
  int N;
  vector<lower=0>[N] y;
}

parameters {
  real<lower = 0> shape;
  real<lower = 0> scale;  
}

model {
  y ~ gamma(shape, scale);
  shape ~ lognormal(0, 1);
  scale ~ lognormal(0, 1.5);
}
"

model_1 <- cmdstan_model(write_stan_file(stan_code_1))



sbc_backend_1 <- cmdstan_sample_SBC_backend(model_1, 
                                            iter_warmup = 500, iter_sampling = 200, chains = 1)


```

```{r}
set.seed(2258334)
n_datasets <- 10
thin <- 4

generator_func <- function(N) {
  shape <- rlnorm(1, meanlog =  0, sdlog = 1)
  scale <- rlnorm(1, meanlog = 0, sdlog = 1.5)
  
  y <- rgamma(N, shape = shape, scale = scale)
  if(any(y == 0)) {
    warning("Generated zero, replacing with small values")
    y[y == 0] <- .Machine$double.eps
  }
  
  list(
    parameters = list(
      shape = shape,
      scale = scale),
    generated = list(
      N = N,
      y = y)
  )
}


N <- 40
datasets <- generate_datasets(
  list_function_SBC_generator(generator_func, N = N), 
  n_datasets)

```

```{r}
results1 <- compute_results(datasets, sbc_backend_1)
```

10 simulations are enough to see something is wrong with the model. We even see the issue is primarily with the `sigma` parameter!

```{r}
plot_hist(results1$ranks, par = "shape")
plot_ecdf_diff(results1, var = "shape")
plot_hist(results1$ranks, par = "scale")
plot_ecdf_diff(results1, var = "scale")
```

So we see that the simulation does not match the model. In practice, the problem may lie with the simulation, with the model or both. Here, we'll assume that the simulation is correct - we really wanted to work with scale and fix the model to match. I.e. we still represent scale in our model, but invert it to get rate before using Stan's `gamma` distribution:


```{r}
stan_code_2 <- "
data {
  int N;
  vector<lower=0>[N] y;
}

parameters {
  real<lower = 0> shape;
  real<lower = 0> scale;  
}

model {
  y ~ gamma(shape, inv(scale));
  shape ~ lognormal(0, 1);
  scale ~ lognormal(0, 1.5);
}
"

model_2 <- cmdstan_model(write_stan_file(stan_code_2))

sbc_backend_2 <- cmdstan_sample_SBC_backend(model_2, 
                                            iter_warmup = 500, iter_sampling = 200, chains = 1)


```


```{r}
results2 <- compute_results(datasets, sbc_backend_2)
```

No obvious problems here, but obviously if we wanted to be sure, we should have ran a lot more simulations.

```{r}
plot_hist(results2$ranks, par = "shape")
plot_ecdf_diff(results2, var = "shape")
plot_hist(results2$ranks, par = "scale")
plot_ecdf_diff(results2, var = "scale")
```


