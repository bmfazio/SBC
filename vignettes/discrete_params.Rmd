---
title: "SBC with discrete parameters"
author: "Martin ModrÃ¡k"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: yes
vignette: >
  %\VignetteIndexEntry{SBC with discrete parameters}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include = FALSE}
library(SBC); 
library(ggplot2)

use_cmdstanr <- TRUE # Set to false to use rstan instead

if(use_cmdstanr) {
  library(cmdstanr)
} else {
  library(rstan)
}

# Multiprocessing support
library(future)
plan(multisession)

# The fits are very fast and we fit just a few, 
# so we force a minimum chunk size to reduce overhead of
# paralellization and decrease computation time.
options(SBC.min_chunk_size = 5)

```

Model from:
https://mc-stan.org/docs/2_26/stan-users-guide/change-point-section.html


```{r}
stan_code_1 <- "
data {
  real<lower=0> r_e;
  real<lower=0> r_l;

  int<lower=1> T;
  int<lower=0> y[T];
}
transformed data {
  real log_unif;
  log_unif = -log(T);
}
parameters {
  real<lower=0> e;
  real<lower=0> l;
}
transformed parameters {
  vector[T] lp;
  lp = rep_vector(log_unif, T);
  for (s in 1:T)
    for (t in 1:T)
      lp[s] = lp[s] + poisson_lpmf(y[t] | t < s ? e : l);
}
model {
  e ~ exponential(r_e);
  l ~ exponential(r_l);
  target += log_sum_exp(lp);
}

generated quantities {
  int<lower=1,upper=T> s;
  s = categorical_logit_rng(lp);
}
"

if(use_cmdstanr) {
  model_1 <- cmdstan_model(write_stan_file(stan_code_1))
  backend_1 <- SBC_backend_cmdstan_sample(model_1)
} else {
  model_1 <- stan_model(model_code = stan_code_1)
  backend_1 <- SBC_backend_rstan_sample(model_1)
}




```
```{r}
generate_single_dataset_1 <- function(T, r_e, r_l) {
  e <- rexp(1, r_e)
  l <- rexp(1, r_l)
  s <- sample.int(T, size = 1)
  
  y <- array(NA_real_, T)
  for(t in 1:T) {
    if(t <= s) {
      rate <- e
    } else {
      rate <- l
    }
    y[t] <- rpois(1, rate) 
  }
  
  list(
    parameters = list(
      e = e, l = l, s = s
    ), generated = list(
      T = T,
      r_e = r_e,
      r_l = r_l,
      y = y
    )
  )
}

generator_1 <- SBC_generator_function(generate_single_dataset_1, T = 5, r_e = 0.5, r_l = 0.1)
```


```{r}
set.seed(85394672)
datasets_1 <- generate_datasets(generator_1, 30)

```

```{r}
results_1 <- compute_results(datasets_1, backend_1)
```
TODO the diagnostics are false positives, because Rhat and ESS don't work very well for discrete parameters.
We need to figure out how to handle this better.

We can quickly note that the statistics for the `s` parameter are extreme - many ranks of 0 and _extreme_ z-scores, including -Infinity. Seing just one or two such fits should be enough to convince us that there is something fundamentally wrong.

```{r}
dplyr::filter(results_1$stats, parameter == "s") 
```


Inspecting the statistics shows that quite often, the model is quite sure of the value of `s` while the simulated value is just one less. 

Looking at the ecdf_diff plot we see that this seems to compromise heavily the inference for `s`, but the other parmaters do not show such bad behaviour.

```{r}
plot_ecdf_diff(results_1)
```

So what happened? After some inspection, you may notice that the simulator does not match the model - the model takes the early rate (`e`) for points `t < s` while the simulator takes `e` for points `t <=  s`, so there is effectively a shift by one time point between the simulator and the model. So let's assume that we beleive that the Stan model is in fact right. We therfore updated the simulator to match the model:


```{r}
generate_single_dataset_2 <- function(T, r_e, r_l) {
  e <- rexp(1, r_e)
  l <- rexp(1, r_l)
  s <- sample.int(T, size = 1)
  
  y <- array(NA_real_, T)
  for(t in 1:T) {
    if(t < s) { ### <--- Only change here
      rate <- e
    } else {
      rate <- l
    }
    y[t] <- rpois(1, rate) 
  }
  
  list(
    parameters = list(
      e = e, l = l, s = s
    ), generated = list(
      T = T,
      r_e = r_e,
      r_l = r_l,
      y = y
    )
  )
}

generator_2 <- SBC_generator_function(generate_single_dataset_2, T = 5, r_e = 0.5, r_l = 0.1)
```



```{r}
set.seed(5846502)
datasets_2 <- generate_datasets(generator_2, 30)
results_2 <- compute_results(datasets_2, backend_1)
plot_ecdf_diff(results_2)
```

Looks good, so let us add some more SBC steps to make sure the model behaves well.

```{r}
set.seed(54321488)
datasets_3 <- generate_datasets(generator_2, 100)
results_3 <- compute_results(datasets_3, backend_1)

results_all <- bind_results(results_2, results_3)
plot_ecdf_diff(results_all)
```


Now - as far as this amount of SBC steps can see, the model is good and we get good behaviour for both the continuous and the discrete parameters.

